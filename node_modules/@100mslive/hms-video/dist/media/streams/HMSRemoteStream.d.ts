import HMSSubscribeConnection from '../../connection/subscribe';
import HMSMediaStream from './HMSMediaStream';
import { HMSSimulcastLayer } from '../../interfaces';
/** @internal */
export default class HMSRemoteStream extends HMSMediaStream {
    private readonly connection;
    private audio;
    private video;
    constructor(nativeStream: MediaStream, connection: HMSSubscribeConnection);
    setAudio(enabled: boolean): void;
    /**
     * Sets the video layer after receiving new state from SFU. This is used when server side subscribe
     * degradation is ON.
     * @param layer is simulcast layer to be set
     * @param identifier is stream identifier to be printed in logs
     */
    setVideoLayerLocally(layer: HMSSimulcastLayer, identifier: string): void;
    /**
     * Sets the video layer and updates the track state to SFU via api datachannel. This is used when client
     * side subscribe degradation is ON or client unsubscribes the current track.
     * @param layer is simulcast layer to be set
     * @param identifier is stream identifier to be printed in logs
     */
    setVideoLayer(layer: HMSSimulcastLayer, identifier: string): void;
    getSimulcastLayer(): HMSSimulcastLayer;
    isAudioSubscribed(): boolean;
    /**
     * send the expected state of the stream to SFU over data channel.
     * the video field is optional from SFU's perspective but audio should be
     * passed everytime.
     * We don't pass in the video field, if only audio needs to subscribed/unsubscribed,
     * else there is a chance of mismatch between states in case of degradation. If
     * a degraded track is (audio) muted, a video layer false will be sent which to
     * SFU will appear as if remove sink was called and the track will never be recovered.
     * @private
     */
    private syncWithApiChannel;
}
